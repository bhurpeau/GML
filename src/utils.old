import pandas as pd
import numpy as np
import geopandas as gpd
import fiona 
import torch
from shapely.geometry import Point 
from shapely.ops import transform 
from sklearn.preprocessing import MinMaxScaler
WFS_ENDPOINT = "https://data.geopf.fr/wfs/ows" 
PLU_LAYER_NAME = "wfs_du:zone_urba" 
SCALER = MinMaxScaler()

# --- 1. FONCTIONS D'ACQUISITION ET DE PRÉ-TRAITEMENT SIG ---

def normalize_features(df, columns_to_normalize, scal=SCALER):
    """Applique la normalisation Min-Max aux colonnes spécifiées."""
    # Fit le scaler uniquement sur les colonnes non-NA
    if not df[columns_to_normalize].empty:
        df[columns_to_normalize] = SCALER.fit_transform(df[columns_to_normalize])
    return df
    
def telecharger_donnees_plu(insee_code):
    partition_value = f'DU_{insee_code}'
    cql_filter = f"partition='{partition_value}'"
    
    wfs_request_url = (
        f'WFS:{WFS_ENDPOINT}?service=WFS&request=GetFeature&typename={PLU_LAYER_NAME}&version=2.0.0'
        f'&outputFormat=json&cql_filter={cql_filter}'
    )
   
    try:
        # Utilisation d'un timeout pour les grands serveurs
        gdf_plu_zones = gpd.read_file(wfs_request_url) 
        if gdf_plu_zones.empty:
             print(f"Succès de la requête, mais 0 zones retournées. {insee_code} n'est peut-être couverte par un PLU/PLUI")
             return None
             
        gdf_plu_zones = gdf_plu_zones.set_crs("EPSG:4326", allow_override=True)
        # 2. Inverser les coordonnées si elles sont lues à l'envers (Lat, Lon)
        gdf_plu_zones['geometry'] = gdf_plu_zones.geometry.apply(lambda geom: transform(lambda x, y: (y, x), geom))
        return gdf_plu_zones

    except Exception as e:
        print(f"Échec critique du WFS : {e}")
        return None

def perform_semantic_sjoin(gdf_parcelles, gdf_usage_sol):    
    # 1. Normalisation des CRS (CRUCIAL)
    TARGET_CRS = "EPSG:2154" # Lambert 93 pour la France Métropolitaine
    gdf_usage_sol = gdf_usage_sol.rename(columns={'libelle': 'LIBELLE','typezone':'TYPEZONE'})
    # a) Normaliser les Parcelles
    if gdf_parcelles.crs is None or gdf_parcelles.crs != TARGET_CRS:
        # Tenter de définir le CRS si non défini (souvent 4326 si c'est du GeoJSON/WKT)
        if gdf_parcelles.crs is None:
            # Si le Cadastre est en WGS84 (lat/lon), définir 4326 puis reprojeter
            print("Définition temporaire du CRS des Parcelles à EPSG:4326...")
            gdf_parcelles = gdf_parcelles.set_crs("EPSG:4326", allow_override=True)
            
        print(f"Reprojection des Parcelles vers {TARGET_CRS}...")
        gdf_parcelles = gdf_parcelles.to_crs(TARGET_CRS)
    # b) Normaliser les Zones PLU
    if gdf_usage_sol.crs is None or gdf_usage_sol.crs != TARGET_CRS:
        # Le WFS est souvent en 4326, donc on le reprojette
        if gdf_usage_sol.crs is None:
             print("Définition temporaire du CRS des Zones PLU à EPSG:4326...")
             gdf_usage_sol = gdf_usage_sol.set_crs("EPSG:4326", allow_override=True)
             
        print(f"Reprojection des Zones PLU vers {TARGET_CRS}...")
        gdf_usage_sol = gdf_usage_sol.to_crs(TARGET_CRS)
    # 2. Préparation pour le Predicate 'within' (Le Point Représentatif)
    # Remplacement du centroïde par le point représentatif (garanti à l'intérieur du polygone)
    
    gdf_parcelles_points = gdf_parcelles.copy()
    
    # MODIFICATION CRITIQUE : Utiliser .representative_point() au lieu de .centroid
    print("Calcul du point représentatif des Parcelles (point garanti dans la géométrie)...")
    gdf_parcelles_points['geometry'] = gdf_parcelles_points['geometry'].apply(lambda x: x.representative_point())


    # 3. Jointure Spatiale Robuste
    # On joint les points représentatifs des parcelles avec les polygones de zone PLU.
    # Predicate='within' : vérifie si le point est DANS la zone PLU
    
    print("Exécution de la jointure spatiale (Parcelle.ReprensentativePoint WITHIN Zone PLU)...")
    
    # Jointure pour récupérer le code PLU
    gdf_parcelles_enriched = gdf_parcelles_points.sjoin(
        gdf_usage_sol[['LIBELLE', 'TYPEZONE', 'geometry']], # Sélectionner uniquement la géométrie et la feature sémantique
        how='left', 
        predicate='within'
    )
    
     
    # Conserver les colonnes utiles pour le GML (on garde l'ID de la parcelle)
    final_features = gdf_parcelles_enriched[['id', 'superficie','LIBELLE','TYPEZONE']].copy()
    final_features = final_features.merge(gdf_parcelles[['id','geometry']], how='left', on='id')
    # Retourner les features enrichies (la colonne PLU_LIBELLE est ajoutée)
    return final_features

def load_and_prepare_real_data(gdf_adr, gdf_bat, gdf_par):    
    TARGET_CRS = "EPSG:2154"
    
    # 1.2 Normalisation des CRS (Lambert 93)
    # Bien que les GeoJSON soient en 2154, la reprojection garantit l'alignement.
    gdf_adr = gdf_adr.to_crs(TARGET_CRS)
    gdf_bat = gdf_bat.to_crs(TARGET_CRS)
    gdf_par = gdf_par.to_crs(TARGET_CRS)
    
    gdf_adr = gdf_adr.rename(columns={'id': 'id_adr'}).assign(id_adr=lambda x: x['id_adr'].astype(str))
    gdf_bat = gdf_bat.rename(columns={'cleabs': 'id_bat', 'hauteur': 'hauteur', 'surface': 'surface'}).assign(id_bat=lambda x: x['id_bat'].astype(str),
                                                                                                             hauteur=lambda x: pd.to_numeric(x['hauteur'], 
                                                                                                                                             errors='coerce').fillna(0).astype(np.float32),
                                                                                                             surface=lambda x: pd.to_numeric(x['surface'], 
                                                                                                                                             errors='coerce').fillna(0).astype(np.float32))
    gdf_par = gdf_par.rename(columns={'id': 'id_par', 'superficie': 'superficie'}).assign(id_par=lambda x: x['id_par'].astype(str),
                                                                                          superficie=lambda x: pd.to_numeric(x['superficie'], 
                                                                                                                             errors='coerce').fillna(0).astype(np.float32))

    gdf_par['LIBELLE'] = gdf_par['LIBELLE'].fillna('HORS_PLU')
    gdf_par['TYPEZONE'] = gdf_par['TYPEZONE'].fillna('HORS_PLU')
    print(f"Bâtiments: {len(gdf_bat)} | Parcelles: {len(gdf_par)} | Adresses: {len(gdf_adr)}")
    
    # --- 1.3. Encodage des Features Sémantiques (PLU) ---

    # Le PLU est déjà dans le fichier parcelles.geojson sous 'LIBELLE' et 'TYPEZONE'
    df_plu_encoded = pd.get_dummies(gdf_par[['LIBELLE', 'TYPEZONE']], prefix=['PLU_LIBELLE', 'TYPEZONE'])
    gdf_adr['x'] = gdf_adr.geometry.x
    gdf_adr['y'] = gdf_adr.geometry.y
    
    gdf_adr = normalize_features(gdf_adr, ['lon', 'lat', 'x', 'y'])
    gdf_bat = normalize_features(gdf_bat, ['hauteur', 'surface'])
    gdf_par = normalize_features(gdf_par, ['superficie'])
    # Assurer que 'superficie' est utilisé et que toutes les features sont numériques
    par_features_base = gdf_par[['superficie']].values.astype(np.float32)
    par_features = np.hstack([par_features_base, df_plu_encoded.values])
    
    # --- 1.4. Création des Relations (Arêtes) ---
    
    # A) Relation Bâtiment -> Parcelle (Lien pondéré par intersection)
    print("Calcul de la relation Bâtiment -> Parcelle (Intersection)...")

    # Calcul de l'intersection: sjoin pour identifier les paires (Bâtiment, Parcelle)
    # Nous utilisons 'intersects' et nous filtrerons le bruit par pondération
    # Il est crucial de s'assurer que gdf_par n'est pas déjà des points (vérifiez l'upload)
    
    # Si le GeoJSON des parcelles est un Point (selon l'extrait), on utilise 'contains'
    if gdf_par.iloc[0].geometry.geom_type == 'Point':
        # Si parcelles.geojson est fait de points, nous joignons les Bâtiments qui contiennent ces points
        sjoin_bp = gpd.sjoin(gdf_par, gdf_bat, how='left', predicate='within', lsuffix='par', rsuffix='bat')
    else:
        # Si parcelles sont des polygones, nous faisons une intersection polygonale
        sjoin_bp = gpd.sjoin(gdf_bat, gdf_par, how='left', predicate='intersects', lsuffix='bat', rsuffix='par')

    # Créer les arêtes (Bâtiment ID -> Parcelle ID)
    edge_index_bp_df = sjoin_bp[['id_bat', 'id_par']].dropna().reset_index(drop=True)
    
    # 1. Joindre les géométries
    sjoin_geom = gpd.sjoin(gdf_bat[['id_bat', 'geometry']], gdf_par[['id_par', 'geometry']], how='left', predicate='intersects', lsuffix='bat', rsuffix='par')
    
    # 2. Calculer le ratio d'intersection
    def calculate_intersection_ratio(row):
        # Sécuriser contre les polygones invalides ou nuls
        if row['geometry_bat'] and row['geometry_par'] and row['geometry_bat'].area > 0:
            try:
                intersection = row['geometry_bat'].intersection(row['geometry_par'])
                # Retourne le pourcentage d'intersection (poids entre 0 et 1)
                return intersection.area / row['geometry_bat'].area
            except Exception:
                return 0.0
        return 0.0
    
    edge_index_bp_df['intersection_perc'] = sjoin_geom.apply(calculate_intersection_ratio, axis=1)
    
    # B) Relation Adresse -> Bâtiment (Lien d'accès)
    print("Calcul de la relation Adresse -> Bâtiment (Point dans Polygone)...")
    
    # sjoin pour trouver le Bâtiment qui contient le point d'Adresse
    MAX_DISTANCE_METERS = 100 # Recherche du bâtiment le plus proche dans un rayon de 100m
    sjoin_ab = gpd.sjoin_nearest(
        gdf_adr, 
        gdf_bat, 
        how='left', 
        max_distance=MAX_DISTANCE_METERS, 
        lsuffix='adr', 
        rsuffix='bat'
    )
    # Sjoin_nearest crée une seule entrée pour chaque adresse
    edge_index_ab_df = sjoin_ab[['id_adr', 'id_bat']].dropna().reset_index(drop=True)

    # --- 1.5. Conversion Finale pour PyTorch ---
       
    # Création des Mappings ID réel -> Index numérique
    adr_map = {id: i for i, id in enumerate(gdf_adr['id_adr'].unique())}
    bat_map = {id: i for i, id in enumerate(gdf_bat['id_bat'].unique())}
    par_map = {id: i for i, id in enumerate(gdf_par['id_par'].unique())}
    
    # Conversion des DataFrames d'arêtes en indices numériques
    edge_index_bp_df['bat_src_idx'] = edge_index_bp_df['id_bat'].map(bat_map)
    edge_index_bp_df['par_dst_idx'] = edge_index_bp_df['id_par'].map(par_map)
    edge_index_ab_df['adr_src_idx'] = edge_index_ab_df['id_adr'].map(adr_map)
    edge_index_ab_df['bat_dst_idx'] = edge_index_ab_df['id_bat'].map(bat_map)
    
    # Création des tenseurs d'index et d'attributs
    edge_index_bp = torch.tensor(edge_index_bp_df[['bat_src_idx', 'par_dst_idx']].values.T.astype(np.int64), dtype=torch.long)
    edge_attr_bp = torch.tensor(edge_index_bp_df[['intersection_perc']].values, dtype=torch.float)
    edge_index_ab = torch.tensor(edge_index_ab_df[['adr_src_idx', 'bat_dst_idx']].values.T.astype(np.int64), dtype=torch.long)
    
    # Tenseurs de Features (maintenant NORMALISÉS)
    adr_x = torch.tensor(gdf_adr[['x', 'y']].values.astype(np.float32), dtype=torch.float)
    bat_x = torch.tensor(gdf_bat[['hauteur', 'surface']].values.astype(np.float32), dtype=torch.float)
    par_x = torch.tensor(par_features, dtype=torch.float)
    
    print(f"\nDimensions des tenseurs (Features normalisées):")
    print(f"  Adresse: {adr_x.shape}")
    print(f"  Bâtiment: {bat_x.shape}")
    print(f"  Parcelle: {par_x.shape}")


    return adr_x, bat_x, par_x, edge_index_bp, edge_attr_bp, edge_index_ab, bat_map, par_map, adr_map